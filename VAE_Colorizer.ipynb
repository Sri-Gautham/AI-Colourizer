{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "ip = genfromtxt('input.csv', delimiter=',')\n",
    "color = genfromtxt('color.csv', delimiter=',')\n",
    "test_data = genfromtxt('data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48894, 9), (48894, 3), (231401, 9))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip/=255\n",
    "color/=255\n",
    "test_data/=255\n",
    "ip.shape, color.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dset size - 39115 \n",
      "Test dset size - 9779\n"
     ]
    }
   ],
   "source": [
    "data_size = ip.shape[0]\n",
    "val_split = 0.2\n",
    "val_size = round(val_split*data_size)\n",
    "val_ix = np.random.choice(data_size, val_size, replace=False)\n",
    "train_ix = np.array(list(set(range(data_size))-set(val_ix)))\n",
    "print('Train dset size - {} \\nTest dset size - {}'.format(train_ix.size, val_ix.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = ip[val_ix[:-3]], color[val_ix[:-3]]\n",
    "train_ix = np.append(train_ix, val_ix[-1])\n",
    "x_train, y_train = ip[train_ix], color[train_ix]\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 4\n",
    "latent_dim = 512\n",
    "x = Input(batch_shape=(None, 9))\n",
    "h = Dense(64, activation='relu')(x)\n",
    "h = Dense(256, activation='relu')(x)\n",
    "h = Dropout(0.2)(h)\n",
    "#h = Dense(latent_dim, activation='relu')(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_std = 1.0\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = 4\n",
    "    \n",
    "    if(z_mean.shape[0]!=64):\n",
    "        print(z_mean.shape[0])\n",
    "        batch_size = z_mean.shape[0]\n",
    "        \n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h1 = Dense(256, activation='relu')\n",
    "decoder_h2 = Dense(64, activation='relu')\n",
    "decoder_mean = Dense(3, activation='sigmoid')\n",
    "h_decoded = decoder_h1(z)\n",
    "h_decoded = Dropout(0.2)(h_decoded)\n",
    "h_decoded = decoder_h2(h_decoded)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h2(decoder_h1(decoder_input))\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "def vae_loss(y_train, x_decoded_mean):\n",
    "    xent_loss = losses.binary_crossentropy(y_train, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39116 samples, validate on 9776 samples\n",
      "Epoch 1/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.6219 - acc: 0.5166 - val_loss: 0.6066 - val_acc: 0.5516\n",
      "Epoch 2/100\n",
      "39116/39116 [==============================] - 60s 2ms/step - loss: 0.6091 - acc: 0.5532 - val_loss: 0.5970 - val_acc: 0.5695\n",
      "Epoch 3/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.6033 - acc: 0.5571 - val_loss: 0.5932 - val_acc: 0.5466\n",
      "Epoch 4/100\n",
      "39116/39116 [==============================] - 63s 2ms/step - loss: 0.6002 - acc: 0.5632 - val_loss: 0.5975 - val_acc: 0.5364\n",
      "Epoch 5/100\n",
      "39116/39116 [==============================] - 68s 2ms/step - loss: 0.5994 - acc: 0.5604 - val_loss: 0.5975 - val_acc: 0.5626\n",
      "Epoch 6/100\n",
      "39116/39116 [==============================] - 66s 2ms/step - loss: 0.5992 - acc: 0.5584 - val_loss: 0.5908 - val_acc: 0.5708\n",
      "Epoch 7/100\n",
      "39116/39116 [==============================] - 65s 2ms/step - loss: 0.5982 - acc: 0.5634 - val_loss: 0.5914 - val_acc: 0.5844\n",
      "Epoch 8/100\n",
      "39116/39116 [==============================] - 69s 2ms/step - loss: 0.5983 - acc: 0.5637 - val_loss: 0.5928 - val_acc: 0.5614\n",
      "Epoch 9/100\n",
      "39116/39116 [==============================] - 68s 2ms/step - loss: 0.5979 - acc: 0.5683 - val_loss: 0.5890 - val_acc: 0.5862\n",
      "Epoch 10/100\n",
      "39116/39116 [==============================] - 70s 2ms/step - loss: 0.5973 - acc: 0.5674 - val_loss: 0.5885 - val_acc: 0.5939\n",
      "Epoch 11/100\n",
      "39116/39116 [==============================] - 71s 2ms/step - loss: 0.5969 - acc: 0.5720 - val_loss: 0.5944 - val_acc: 0.5339\n",
      "Epoch 12/100\n",
      "39116/39116 [==============================] - 72s 2ms/step - loss: 0.5968 - acc: 0.5677 - val_loss: 0.5947 - val_acc: 0.5919\n",
      "Epoch 13/100\n",
      "39116/39116 [==============================] - 72s 2ms/step - loss: 0.5965 - acc: 0.5724 - val_loss: 0.5923 - val_acc: 0.5497\n",
      "Epoch 14/100\n",
      "39116/39116 [==============================] - 73s 2ms/step - loss: 0.5959 - acc: 0.5765 - val_loss: 0.5905 - val_acc: 0.5831\n",
      "Epoch 15/100\n",
      "39116/39116 [==============================] - 70s 2ms/step - loss: 0.5963 - acc: 0.5719 - val_loss: 0.5896 - val_acc: 0.5721\n",
      "Epoch 16/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5961 - acc: 0.5696 - val_loss: 0.6014 - val_acc: 0.5045\n",
      "Epoch 17/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5958 - acc: 0.5730 - val_loss: 0.5878 - val_acc: 0.5963\n",
      "Epoch 18/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5958 - acc: 0.5722 - val_loss: 0.6063 - val_acc: 0.4713\n",
      "Epoch 19/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5960 - acc: 0.5742 - val_loss: 0.5892 - val_acc: 0.5799\n",
      "Epoch 20/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5961 - acc: 0.5761 - val_loss: 0.5905 - val_acc: 0.5523\n",
      "Epoch 21/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5954 - acc: 0.5770 - val_loss: 0.5874 - val_acc: 0.5879\n",
      "Epoch 22/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5956 - acc: 0.5761 - val_loss: 0.5900 - val_acc: 0.6012\n",
      "Epoch 23/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5948 - acc: 0.5802 - val_loss: 0.5842 - val_acc: 0.5975\n",
      "Epoch 24/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5948 - acc: 0.5795 - val_loss: 0.5863 - val_acc: 0.5989\n",
      "Epoch 25/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5941 - acc: 0.5789 - val_loss: 0.5866 - val_acc: 0.5964\n",
      "Epoch 26/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5932 - acc: 0.5831 - val_loss: 0.5845 - val_acc: 0.5997\n",
      "Epoch 27/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5925 - acc: 0.5855 - val_loss: 0.5844 - val_acc: 0.5953\n",
      "Epoch 28/100\n",
      "39116/39116 [==============================] - 55s 1ms/step - loss: 0.5930 - acc: 0.5879 - val_loss: 0.5825 - val_acc: 0.6129\n",
      "Epoch 29/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5932 - acc: 0.5859 - val_loss: 0.5893 - val_acc: 0.6031\n",
      "Epoch 30/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5936 - acc: 0.5841 - val_loss: 0.5884 - val_acc: 0.6152\n",
      "Epoch 31/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5934 - acc: 0.5888 - val_loss: 0.5881 - val_acc: 0.6158\n",
      "Epoch 32/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5938 - acc: 0.5875 - val_loss: 0.5845 - val_acc: 0.6079\n",
      "Epoch 33/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5931 - acc: 0.5898 - val_loss: 0.5821 - val_acc: 0.6027\n",
      "Epoch 34/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5940 - acc: 0.5875 - val_loss: 0.5859 - val_acc: 0.6036\n",
      "Epoch 35/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5945 - acc: 0.5877 - val_loss: 0.5872 - val_acc: 0.5747\n",
      "Epoch 36/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5945 - acc: 0.5857 - val_loss: 0.5892 - val_acc: 0.5879\n",
      "Epoch 37/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5950 - acc: 0.5851 - val_loss: 0.5844 - val_acc: 0.5947\n",
      "Epoch 38/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5946 - acc: 0.5864 - val_loss: 0.5872 - val_acc: 0.5686\n",
      "Epoch 39/100\n",
      "39116/39116 [==============================] - 55s 1ms/step - loss: 0.5954 - acc: 0.5847 - val_loss: 0.5870 - val_acc: 0.5914\n",
      "Epoch 40/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5944 - acc: 0.5873 - val_loss: 0.5827 - val_acc: 0.6071\n",
      "Epoch 41/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5942 - acc: 0.5876 - val_loss: 0.5888 - val_acc: 0.6057\n",
      "Epoch 42/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5945 - acc: 0.5895 - val_loss: 0.5887 - val_acc: 0.5878\n",
      "Epoch 43/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5944 - acc: 0.5866 - val_loss: 0.5850 - val_acc: 0.6126\n",
      "Epoch 44/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5943 - acc: 0.5870 - val_loss: 0.5875 - val_acc: 0.5895\n",
      "Epoch 45/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5946 - acc: 0.5909 - val_loss: 0.5844 - val_acc: 0.6007\n",
      "Epoch 46/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5947 - acc: 0.5875 - val_loss: 0.5850 - val_acc: 0.6126\n",
      "Epoch 47/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5949 - acc: 0.5871 - val_loss: 0.5861 - val_acc: 0.6137\n",
      "Epoch 48/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5953 - acc: 0.5861 - val_loss: 0.5841 - val_acc: 0.6122\n",
      "Epoch 49/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5951 - acc: 0.5868 - val_loss: 0.5841 - val_acc: 0.6037\n",
      "Epoch 50/100\n",
      "39116/39116 [==============================] - 73s 2ms/step - loss: 0.5953 - acc: 0.5894 - val_loss: 0.5864 - val_acc: 0.5956\n",
      "Epoch 51/100\n",
      "39116/39116 [==============================] - 65s 2ms/step - loss: 0.5976 - acc: 0.5798 - val_loss: 0.5841 - val_acc: 0.6095\n",
      "Epoch 52/100\n",
      "39116/39116 [==============================] - 60s 2ms/step - loss: 0.5963 - acc: 0.5870 - val_loss: 0.5833 - val_acc: 0.6137\n",
      "Epoch 53/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5953 - acc: 0.5854 - val_loss: 0.5830 - val_acc: 0.6146\n",
      "Epoch 54/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5944 - acc: 0.5896 - val_loss: 0.5874 - val_acc: 0.6078\n",
      "Epoch 55/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5946 - acc: 0.5876 - val_loss: 0.5849 - val_acc: 0.5833\n",
      "Epoch 56/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5951 - acc: 0.5876 - val_loss: 0.5929 - val_acc: 0.5765\n",
      "Epoch 57/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5964 - acc: 0.5819 - val_loss: 0.5906 - val_acc: 0.5677\n",
      "Epoch 58/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5966 - acc: 0.5809 - val_loss: 0.5860 - val_acc: 0.5925\n",
      "Epoch 59/100\n",
      "39116/39116 [==============================] - 59s 1ms/step - loss: 0.5965 - acc: 0.5815 - val_loss: 0.5922 - val_acc: 0.5902\n",
      "Epoch 60/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5963 - acc: 0.5821 - val_loss: 0.5890 - val_acc: 0.6012\n",
      "Epoch 61/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5964 - acc: 0.5820 - val_loss: 0.5854 - val_acc: 0.5976\n",
      "Epoch 62/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5968 - acc: 0.5818 - val_loss: 0.5861 - val_acc: 0.6031\n",
      "Epoch 63/100\n",
      "39116/39116 [==============================] - 62s 2ms/step - loss: 0.5967 - acc: 0.5829 - val_loss: 0.5913 - val_acc: 0.6079\n",
      "Epoch 64/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5969 - acc: 0.5842 - val_loss: 0.5869 - val_acc: 0.5992\n",
      "Epoch 65/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5969 - acc: 0.5797 - val_loss: 0.5869 - val_acc: 0.6039\n",
      "Epoch 66/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5971 - acc: 0.5810 - val_loss: 0.5853 - val_acc: 0.6008\n",
      "Epoch 67/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5968 - acc: 0.5826 - val_loss: 0.5888 - val_acc: 0.6038\n",
      "Epoch 68/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5971 - acc: 0.5817 - val_loss: 0.5882 - val_acc: 0.5901\n",
      "Epoch 69/100\n",
      "39116/39116 [==============================] - 59s 2ms/step - loss: 0.5971 - acc: 0.5805 - val_loss: 0.5869 - val_acc: 0.6110\n",
      "Epoch 70/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5978 - acc: 0.5818 - val_loss: 0.5878 - val_acc: 0.6002\n",
      "Epoch 71/100\n",
      "39116/39116 [==============================] - 59s 2ms/step - loss: 0.5988 - acc: 0.5748 - val_loss: 0.5902 - val_acc: 0.5938\n",
      "Epoch 72/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5993 - acc: 0.5698 - val_loss: 0.5921 - val_acc: 0.5830\n",
      "Epoch 73/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5991 - acc: 0.5740 - val_loss: 0.5936 - val_acc: 0.5631\n",
      "Epoch 74/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5983 - acc: 0.5744 - val_loss: 0.5871 - val_acc: 0.5888\n",
      "Epoch 75/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5983 - acc: 0.5732 - val_loss: 0.5888 - val_acc: 0.5685\n",
      "Epoch 76/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5983 - acc: 0.5782 - val_loss: 0.5927 - val_acc: 0.5910\n",
      "Epoch 77/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5984 - acc: 0.5750 - val_loss: 0.5901 - val_acc: 0.5947\n",
      "Epoch 78/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5983 - acc: 0.5725 - val_loss: 0.5876 - val_acc: 0.6195\n",
      "Epoch 79/100\n",
      "39116/39116 [==============================] - 60s 2ms/step - loss: 0.5978 - acc: 0.5752 - val_loss: 0.5872 - val_acc: 0.6144\n",
      "Epoch 80/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5982 - acc: 0.5775 - val_loss: 0.5892 - val_acc: 0.5774\n",
      "Epoch 81/100\n",
      "39116/39116 [==============================] - 68s 2ms/step - loss: 0.5977 - acc: 0.5752 - val_loss: 0.5894 - val_acc: 0.6044\n",
      "Epoch 82/100\n",
      "39116/39116 [==============================] - 66s 2ms/step - loss: 0.5990 - acc: 0.5742 - val_loss: 0.5878 - val_acc: 0.5631\n",
      "Epoch 83/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5982 - acc: 0.5762 - val_loss: 0.5875 - val_acc: 0.6027\n",
      "Epoch 84/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5978 - acc: 0.5754 - val_loss: 0.5872 - val_acc: 0.5987\n",
      "Epoch 85/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5976 - acc: 0.5761 - val_loss: 0.5906 - val_acc: 0.5919\n",
      "Epoch 86/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5978 - acc: 0.5741 - val_loss: 0.5906 - val_acc: 0.6093\n",
      "Epoch 87/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5976 - acc: 0.5764 - val_loss: 0.5861 - val_acc: 0.6018\n",
      "Epoch 88/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5976 - acc: 0.5739 - val_loss: 0.5876 - val_acc: 0.5970\n",
      "Epoch 89/100\n",
      "39116/39116 [==============================] - 55s 1ms/step - loss: 0.5972 - acc: 0.5747 - val_loss: 0.5862 - val_acc: 0.6076\n",
      "Epoch 90/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5972 - acc: 0.5766 - val_loss: 0.5928 - val_acc: 0.5887\n",
      "Epoch 91/100\n",
      "39116/39116 [==============================] - 68s 2ms/step - loss: 0.5978 - acc: 0.5719 - val_loss: 0.5912 - val_acc: 0.6121\n",
      "Epoch 92/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5967 - acc: 0.5796 - val_loss: 0.5852 - val_acc: 0.5997\n",
      "Epoch 93/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5971 - acc: 0.5745 - val_loss: 0.5887 - val_acc: 0.5733\n",
      "Epoch 94/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5964 - acc: 0.5819 - val_loss: 0.5872 - val_acc: 0.6063\n",
      "Epoch 95/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5966 - acc: 0.5804 - val_loss: 0.5908 - val_acc: 0.5760\n",
      "Epoch 96/100\n",
      "39116/39116 [==============================] - 59s 2ms/step - loss: 0.5963 - acc: 0.5766 - val_loss: 0.5862 - val_acc: 0.6045\n",
      "Epoch 97/100\n",
      "39116/39116 [==============================] - 56s 1ms/step - loss: 0.5962 - acc: 0.5768 - val_loss: 0.5882 - val_acc: 0.5769\n",
      "Epoch 98/100\n",
      "39116/39116 [==============================] - 57s 1ms/step - loss: 0.5963 - acc: 0.5785 - val_loss: 0.5846 - val_acc: 0.6127\n",
      "Epoch 99/100\n",
      "39116/39116 [==============================] - 55s 1ms/step - loss: 0.5961 - acc: 0.5803 - val_loss: 0.5864 - val_acc: 0.6034\n",
      "Epoch 100/100\n",
      "39116/39116 [==============================] - 58s 1ms/step - loss: 0.5959 - acc: 0.5796 - val_loss: 0.5875 - val_acc: 0.5899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c23f3051d0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, y_train,\n",
    "        shuffle=True,\n",
    "        epochs=100,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39116 samples, validate on 9776 samples\n",
      "Epoch 1/100\n",
      "39116/39116 [==============================] - 15s 376us/step - loss: 0.6399 - acc: 0.4618 - val_loss: 0.6199 - val_acc: 0.4861\n",
      "Epoch 2/100\n",
      "39116/39116 [==============================] - 16s 405us/step - loss: 0.6177 - acc: 0.5066 - val_loss: 0.6151 - val_acc: 0.5320\n",
      "Epoch 3/100\n",
      "39116/39116 [==============================] - 20s 517us/step - loss: 0.6148 - acc: 0.5293 - val_loss: 0.6127 - val_acc: 0.5453\n",
      "Epoch 4/100\n",
      "39116/39116 [==============================] - 16s 397us/step - loss: 0.6131 - acc: 0.5417 - val_loss: 0.6124 - val_acc: 0.5557\n",
      "Epoch 5/100\n",
      "39116/39116 [==============================] - 16s 399us/step - loss: 0.6123 - acc: 0.5497 - val_loss: 0.6108 - val_acc: 0.5608\n",
      "Epoch 6/100\n",
      "39116/39116 [==============================] - 15s 372us/step - loss: 0.6114 - acc: 0.5592 - val_loss: 0.6150 - val_acc: 0.5638\n",
      "Epoch 7/100\n",
      "39116/39116 [==============================] - 13s 335us/step - loss: 0.6086 - acc: 0.5699 - val_loss: 0.6082 - val_acc: 0.5910\n",
      "Epoch 8/100\n",
      "39116/39116 [==============================] - 13s 332us/step - loss: 0.6036 - acc: 0.5945 - val_loss: 0.6014 - val_acc: 0.6089\n",
      "Epoch 9/100\n",
      "39116/39116 [==============================] - 13s 342us/step - loss: 0.6013 - acc: 0.6006 - val_loss: 0.6064 - val_acc: 0.5859\n",
      "Epoch 10/100\n",
      "39116/39116 [==============================] - 13s 332us/step - loss: 0.6007 - acc: 0.6051 - val_loss: 0.6017 - val_acc: 0.6151\n",
      "Epoch 11/100\n",
      "39116/39116 [==============================] - 13s 339us/step - loss: 0.6009 - acc: 0.6085 - val_loss: 0.5989 - val_acc: 0.6222\n",
      "Epoch 12/100\n",
      "39116/39116 [==============================] - 14s 355us/step - loss: 0.6009 - acc: 0.6073 - val_loss: 0.6090 - val_acc: 0.6211\n",
      "Epoch 13/100\n",
      "39116/39116 [==============================] - 14s 357us/step - loss: 0.6009 - acc: 0.6107 - val_loss: 0.6005 - val_acc: 0.6052\n",
      "Epoch 14/100\n",
      "39116/39116 [==============================] - 14s 366us/step - loss: 0.6010 - acc: 0.6076 - val_loss: 0.6140 - val_acc: 0.5777\n",
      "Epoch 15/100\n",
      "39116/39116 [==============================] - 15s 385us/step - loss: 0.6008 - acc: 0.6107 - val_loss: 0.5983 - val_acc: 0.6169\n",
      "Epoch 16/100\n",
      "39116/39116 [==============================] - 16s 419us/step - loss: 0.6008 - acc: 0.6103 - val_loss: 0.6009 - val_acc: 0.6191\n",
      "Epoch 17/100\n",
      "39116/39116 [==============================] - 21s 536us/step - loss: 0.6005 - acc: 0.6112 - val_loss: 0.6011 - val_acc: 0.6012\n",
      "Epoch 18/100\n",
      "39116/39116 [==============================] - 23s 582us/step - loss: 0.6006 - acc: 0.6110 - val_loss: 0.5967 - val_acc: 0.6304\n",
      "Epoch 19/100\n",
      "39116/39116 [==============================] - 19s 474us/step - loss: 0.6009 - acc: 0.6135 - val_loss: 0.5986 - val_acc: 0.6219\n",
      "Epoch 20/100\n",
      "39116/39116 [==============================] - 16s 415us/step - loss: 0.6012 - acc: 0.6121 - val_loss: 0.6027 - val_acc: 0.6279\n",
      "Epoch 21/100\n",
      "39116/39116 [==============================] - 15s 387us/step - loss: 0.6009 - acc: 0.6106 - val_loss: 0.5999 - val_acc: 0.6258\n",
      "Epoch 22/100\n",
      "39116/39116 [==============================] - 15s 372us/step - loss: 0.6008 - acc: 0.6150 - val_loss: 0.6003 - val_acc: 0.6149\n",
      "Epoch 23/100\n",
      "39116/39116 [==============================] - 16s 398us/step - loss: 0.6012 - acc: 0.6102 - val_loss: 0.6018 - val_acc: 0.6304\n",
      "Epoch 24/100\n",
      "39116/39116 [==============================] - 16s 414us/step - loss: 0.6012 - acc: 0.6147 - val_loss: 0.5962 - val_acc: 0.6374\n",
      "Epoch 25/100\n",
      "39116/39116 [==============================] - 15s 394us/step - loss: 0.6007 - acc: 0.6144 - val_loss: 0.5962 - val_acc: 0.6244\n",
      "Epoch 26/100\n",
      "39116/39116 [==============================] - 15s 385us/step - loss: 0.6009 - acc: 0.6119 - val_loss: 0.5998 - val_acc: 0.6190\n",
      "Epoch 27/100\n",
      "39116/39116 [==============================] - 16s 415us/step - loss: 0.6011 - acc: 0.6126 - val_loss: 0.5982 - val_acc: 0.6312\n",
      "Epoch 28/100\n",
      "39116/39116 [==============================] - 18s 468us/step - loss: 0.6009 - acc: 0.6125 - val_loss: 0.6000 - val_acc: 0.6297\n",
      "Epoch 29/100\n",
      "39116/39116 [==============================] - 17s 431us/step - loss: 0.6010 - acc: 0.6109 - val_loss: 0.5999 - val_acc: 0.6342\n",
      "Epoch 30/100\n",
      "39116/39116 [==============================] - 33s 844us/step - loss: 0.6013 - acc: 0.6108 - val_loss: 0.6102 - val_acc: 0.6177\n",
      "Epoch 31/100\n",
      "39116/39116 [==============================] - 21s 531us/step - loss: 0.6011 - acc: 0.6144 - val_loss: 0.6024 - val_acc: 0.6268\n",
      "Epoch 32/100\n",
      "39116/39116 [==============================] - 17s 427us/step - loss: 0.6017 - acc: 0.6101 - val_loss: 0.5964 - val_acc: 0.6249\n",
      "Epoch 33/100\n",
      "39116/39116 [==============================] - 18s 456us/step - loss: 0.6010 - acc: 0.6105 - val_loss: 0.5998 - val_acc: 0.6283\n",
      "Epoch 34/100\n",
      "39116/39116 [==============================] - 16s 417us/step - loss: 0.6015 - acc: 0.6085 - val_loss: 0.6033 - val_acc: 0.5971\n",
      "Epoch 35/100\n",
      "39116/39116 [==============================] - 16s 403us/step - loss: 0.6013 - acc: 0.6104 - val_loss: 0.6057 - val_acc: 0.6209\n",
      "Epoch 36/100\n",
      "39116/39116 [==============================] - 16s 407us/step - loss: 0.6014 - acc: 0.6132 - val_loss: 0.6034 - val_acc: 0.5986\n",
      "Epoch 37/100\n",
      "39116/39116 [==============================] - 16s 408us/step - loss: 0.6016 - acc: 0.6115 - val_loss: 0.5997 - val_acc: 0.6114\n",
      "Epoch 38/100\n",
      "39116/39116 [==============================] - 16s 403us/step - loss: 0.6018 - acc: 0.6114 - val_loss: 0.5990 - val_acc: 0.6325\n",
      "Epoch 39/100\n",
      "39116/39116 [==============================] - 16s 401us/step - loss: 0.6018 - acc: 0.6117 - val_loss: 0.6023 - val_acc: 0.5926\n",
      "Epoch 40/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.6015 - acc: 0.6117 - val_loss: 0.6101 - val_acc: 0.6171\n",
      "Epoch 41/100\n",
      "39116/39116 [==============================] - 16s 409us/step - loss: 0.6017 - acc: 0.6122 - val_loss: 0.6109 - val_acc: 0.5745\n",
      "Epoch 42/100\n",
      "39116/39116 [==============================] - 18s 465us/step - loss: 0.6024 - acc: 0.6123 - val_loss: 0.6035 - val_acc: 0.5889\n",
      "Epoch 43/100\n",
      "39116/39116 [==============================] - 16s 402us/step - loss: 0.6017 - acc: 0.6104 - val_loss: 0.5983 - val_acc: 0.6243\n",
      "Epoch 44/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.6014 - acc: 0.6118 - val_loss: 0.6078 - val_acc: 0.5874\n",
      "Epoch 45/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.6016 - acc: 0.6096 - val_loss: 0.6035 - val_acc: 0.6298\n",
      "Epoch 46/100\n",
      "39116/39116 [==============================] - 16s 406us/step - loss: 0.6019 - acc: 0.6076 - val_loss: 0.5979 - val_acc: 0.6231\n",
      "Epoch 47/100\n",
      "39116/39116 [==============================] - 16s 402us/step - loss: 0.6016 - acc: 0.6084 - val_loss: 0.6020 - val_acc: 0.5992\n",
      "Epoch 48/100\n",
      "39116/39116 [==============================] - 15s 396us/step - loss: 0.6013 - acc: 0.6100 - val_loss: 0.5995 - val_acc: 0.6150\n",
      "Epoch 49/100\n",
      "39116/39116 [==============================] - 16s 414us/step - loss: 0.6010 - acc: 0.6077 - val_loss: 0.5967 - val_acc: 0.6254\n",
      "Epoch 50/100\n",
      "39116/39116 [==============================] - 16s 409us/step - loss: 0.6008 - acc: 0.6079 - val_loss: 0.5957 - val_acc: 0.6176\n",
      "Epoch 51/100\n",
      "39116/39116 [==============================] - 16s 414us/step - loss: 0.6009 - acc: 0.6058 - val_loss: 0.5977 - val_acc: 0.6144\n",
      "Epoch 52/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.6013 - acc: 0.6067 - val_loss: 0.6013 - val_acc: 0.6197\n",
      "Epoch 53/100\n",
      "39116/39116 [==============================] - 16s 403us/step - loss: 0.6012 - acc: 0.6061 - val_loss: 0.6000 - val_acc: 0.6304\n",
      "Epoch 54/100\n",
      "39116/39116 [==============================] - 16s 399us/step - loss: 0.6007 - acc: 0.6102 - val_loss: 0.5984 - val_acc: 0.6193\n",
      "Epoch 55/100\n",
      "39116/39116 [==============================] - 16s 402us/step - loss: 0.6007 - acc: 0.6080 - val_loss: 0.5996 - val_acc: 0.6276\n",
      "Epoch 56/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.6007 - acc: 0.6066 - val_loss: 0.6002 - val_acc: 0.6304\n",
      "Epoch 57/100\n",
      "39116/39116 [==============================] - 16s 405us/step - loss: 0.6009 - acc: 0.6038 - val_loss: 0.5983 - val_acc: 0.6148\n",
      "Epoch 58/100\n",
      "39116/39116 [==============================] - 16s 399us/step - loss: 0.6010 - acc: 0.6040 - val_loss: 0.5966 - val_acc: 0.6231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.6004 - acc: 0.6096 - val_loss: 0.6015 - val_acc: 0.6171\n",
      "Epoch 60/100\n",
      "39116/39116 [==============================] - 18s 453us/step - loss: 0.6007 - acc: 0.6072 - val_loss: 0.6055 - val_acc: 0.5763\n",
      "Epoch 61/100\n",
      "39116/39116 [==============================] - 16s 405us/step - loss: 0.6009 - acc: 0.6055 - val_loss: 0.6027 - val_acc: 0.6166\n",
      "Epoch 62/100\n",
      "39116/39116 [==============================] - 16s 398us/step - loss: 0.6011 - acc: 0.6067 - val_loss: 0.6039 - val_acc: 0.6332\n",
      "Epoch 63/100\n",
      "39116/39116 [==============================] - 15s 393us/step - loss: 0.6012 - acc: 0.6077 - val_loss: 0.5976 - val_acc: 0.6176\n",
      "Epoch 64/100\n",
      "39116/39116 [==============================] - 16s 402us/step - loss: 0.6010 - acc: 0.6070 - val_loss: 0.6002 - val_acc: 0.6267\n",
      "Epoch 65/100\n",
      "39116/39116 [==============================] - 16s 397us/step - loss: 0.6011 - acc: 0.6073 - val_loss: 0.6182 - val_acc: 0.6043\n",
      "Epoch 66/100\n",
      "39116/39116 [==============================] - 16s 399us/step - loss: 0.6010 - acc: 0.6069 - val_loss: 0.6000 - val_acc: 0.6246\n",
      "Epoch 67/100\n",
      "39116/39116 [==============================] - 16s 417us/step - loss: 0.6007 - acc: 0.6080 - val_loss: 0.5973 - val_acc: 0.6214\n",
      "Epoch 68/100\n",
      "39116/39116 [==============================] - 16s 421us/step - loss: 0.6006 - acc: 0.6074 - val_loss: 0.5998 - val_acc: 0.6156\n",
      "Epoch 69/100\n",
      "39116/39116 [==============================] - 16s 403us/step - loss: 0.6006 - acc: 0.6091 - val_loss: 0.5987 - val_acc: 0.6251\n",
      "Epoch 70/100\n",
      "39116/39116 [==============================] - 17s 424us/step - loss: 0.6005 - acc: 0.6085 - val_loss: 0.5962 - val_acc: 0.6091\n",
      "Epoch 71/100\n",
      "39116/39116 [==============================] - 16s 414us/step - loss: 0.6004 - acc: 0.6084 - val_loss: 0.5974 - val_acc: 0.6175\n",
      "Epoch 72/100\n",
      "39116/39116 [==============================] - 17s 424us/step - loss: 0.6003 - acc: 0.6095 - val_loss: 0.5987 - val_acc: 0.6206\n",
      "Epoch 73/100\n",
      "39116/39116 [==============================] - 16s 409us/step - loss: 0.6003 - acc: 0.6084 - val_loss: 0.6015 - val_acc: 0.6278\n",
      "Epoch 74/100\n",
      "39116/39116 [==============================] - 16s 411us/step - loss: 0.6000 - acc: 0.6093 - val_loss: 0.5994 - val_acc: 0.6109\n",
      "Epoch 75/100\n",
      "39116/39116 [==============================] - 16s 399us/step - loss: 0.5999 - acc: 0.6106 - val_loss: 0.5993 - val_acc: 0.6321\n",
      "Epoch 76/100\n",
      "39116/39116 [==============================] - 16s 406us/step - loss: 0.5997 - acc: 0.6090 - val_loss: 0.5992 - val_acc: 0.6269\n",
      "Epoch 77/100\n",
      "39116/39116 [==============================] - 16s 401us/step - loss: 0.6000 - acc: 0.6111 - val_loss: 0.6019 - val_acc: 0.6131\n",
      "Epoch 78/100\n",
      "39116/39116 [==============================] - 16s 416us/step - loss: 0.6003 - acc: 0.6099 - val_loss: 0.6001 - val_acc: 0.6141\n",
      "Epoch 79/100\n",
      "39116/39116 [==============================] - 19s 478us/step - loss: 0.6002 - acc: 0.6097 - val_loss: 0.5962 - val_acc: 0.6270\n",
      "Epoch 80/100\n",
      "39116/39116 [==============================] - 16s 411us/step - loss: 0.5999 - acc: 0.6091 - val_loss: 0.6012 - val_acc: 0.6170\n",
      "Epoch 81/100\n",
      "39116/39116 [==============================] - 16s 400us/step - loss: 0.5999 - acc: 0.6076 - val_loss: 0.6022 - val_acc: 0.6367\n",
      "Epoch 82/100\n",
      "39116/39116 [==============================] - 16s 402us/step - loss: 0.5996 - acc: 0.6090 - val_loss: 0.5998 - val_acc: 0.6333\n",
      "Epoch 83/100\n",
      "39116/39116 [==============================] - 16s 398us/step - loss: 0.6000 - acc: 0.6117 - val_loss: 0.5992 - val_acc: 0.6144\n",
      "Epoch 84/100\n",
      "39116/39116 [==============================] - 15s 396us/step - loss: 0.5997 - acc: 0.6094 - val_loss: 0.5964 - val_acc: 0.6296\n",
      "Epoch 85/100\n",
      "39116/39116 [==============================] - 16s 406us/step - loss: 0.5996 - acc: 0.6115 - val_loss: 0.6041 - val_acc: 0.5861\n",
      "Epoch 86/100\n",
      "39116/39116 [==============================] - 16s 405us/step - loss: 0.5995 - acc: 0.6120 - val_loss: 0.5991 - val_acc: 0.6116\n",
      "Epoch 87/100\n",
      "39116/39116 [==============================] - 16s 404us/step - loss: 0.5989 - acc: 0.6096 - val_loss: 0.5972 - val_acc: 0.6249\n",
      "Epoch 88/100\n",
      "39116/39116 [==============================] - 16s 399us/step - loss: 0.5991 - acc: 0.6066 - val_loss: 0.5977 - val_acc: 0.6282\n",
      "Epoch 89/100\n",
      "39116/39116 [==============================] - 20s 502us/step - loss: 0.5997 - acc: 0.6074 - val_loss: 0.5989 - val_acc: 0.6063\n",
      "Epoch 90/100\n",
      "39116/39116 [==============================] - 16s 411us/step - loss: 0.5992 - acc: 0.6074 - val_loss: 0.5984 - val_acc: 0.6278\n",
      "Epoch 91/100\n",
      "39116/39116 [==============================] - 16s 409us/step - loss: 0.5991 - acc: 0.6087 - val_loss: 0.6051 - val_acc: 0.6209\n",
      "Epoch 92/100\n",
      "39116/39116 [==============================] - 17s 437us/step - loss: 0.5990 - acc: 0.6082 - val_loss: 0.5986 - val_acc: 0.6196\n",
      "Epoch 93/100\n",
      "39116/39116 [==============================] - 16s 416us/step - loss: 0.5992 - acc: 0.6077 - val_loss: 0.5983 - val_acc: 0.6259\n",
      "Epoch 94/100\n",
      "39116/39116 [==============================] - 16s 408us/step - loss: 0.5989 - acc: 0.6077 - val_loss: 0.5967 - val_acc: 0.6156\n",
      "Epoch 95/100\n",
      "39116/39116 [==============================] - 22s 566us/step - loss: 0.5991 - acc: 0.6076 - val_loss: 0.6022 - val_acc: 0.6066\n",
      "Epoch 96/100\n",
      "39116/39116 [==============================] - 33s 851us/step - loss: 0.5991 - acc: 0.6064 - val_loss: 0.5978 - val_acc: 0.6200\n",
      "Epoch 97/100\n",
      "39116/39116 [==============================] - 21s 539us/step - loss: 0.5989 - acc: 0.6079 - val_loss: 0.5972 - val_acc: 0.6210\n",
      "Epoch 98/100\n",
      "39116/39116 [==============================] - 20s 513us/step - loss: 0.5990 - acc: 0.6071 - val_loss: 0.5965 - val_acc: 0.6205\n",
      "Epoch 99/100\n",
      "39116/39116 [==============================] - 20s 523us/step - loss: 0.5990 - acc: 0.6068 - val_loss: 0.5978 - val_acc: 0.6278\n",
      "Epoch 100/100\n",
      "39116/39116 [==============================] - 20s 523us/step - loss: 0.5987 - acc: 0.6072 - val_loss: 0.6006 - val_acc: 0.5996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c23fce8f60>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->32->64(z)->32->3\n",
    "vae.fit(x_train, y_train,\n",
    "        shuffle=True,\n",
    "        epochs=100,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=9))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40018 samples, validate on 9779 samples\n",
      "Epoch 1/100\n",
      "40018/40018 [==============================] - 9s 225us/step - loss: 0.0240 - acc: 0.5794 - val_loss: 0.0167 - val_acc: 0.6064\n",
      "Epoch 2/100\n",
      "40018/40018 [==============================] - 7s 173us/step - loss: 0.0181 - acc: 0.6096 - val_loss: 0.0160 - val_acc: 0.6254\n",
      "Epoch 3/100\n",
      "40018/40018 [==============================] - 6s 150us/step - loss: 0.0171 - acc: 0.6245 - val_loss: 0.0152 - val_acc: 0.6296\n",
      "Epoch 4/100\n",
      "40018/40018 [==============================] - 8s 190us/step - loss: 0.0167 - acc: 0.6293 - val_loss: 0.0149 - val_acc: 0.6372\n",
      "Epoch 5/100\n",
      "40018/40018 [==============================] - 8s 201us/step - loss: 0.0165 - acc: 0.6318 - val_loss: 0.0149 - val_acc: 0.6367\n",
      "Epoch 6/100\n",
      "40018/40018 [==============================] - 9s 232us/step - loss: 0.0163 - acc: 0.6381 - val_loss: 0.0164 - val_acc: 0.6139\n",
      "Epoch 7/100\n",
      "40018/40018 [==============================] - 9s 217us/step - loss: 0.0162 - acc: 0.6420 - val_loss: 0.0144 - val_acc: 0.6455\n",
      "Epoch 8/100\n",
      "40018/40018 [==============================] - 7s 170us/step - loss: 0.0160 - acc: 0.6427 - val_loss: 0.0146 - val_acc: 0.6486\n",
      "Epoch 9/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0157 - acc: 0.6495 - val_loss: 0.0152 - val_acc: 0.6615\n",
      "Epoch 10/100\n",
      "40018/40018 [==============================] - 9s 220us/step - loss: 0.0156 - acc: 0.6500 - val_loss: 0.0145 - val_acc: 0.6573\n",
      "Epoch 11/100\n",
      "40018/40018 [==============================] - 8s 189us/step - loss: 0.0156 - acc: 0.6562 - val_loss: 0.0144 - val_acc: 0.6558\n",
      "Epoch 12/100\n",
      "40018/40018 [==============================] - 7s 185us/step - loss: 0.0154 - acc: 0.6573 - val_loss: 0.0144 - val_acc: 0.6739\n",
      "Epoch 13/100\n",
      "40018/40018 [==============================] - 8s 191us/step - loss: 0.0153 - acc: 0.6601 - val_loss: 0.0153 - val_acc: 0.6479\n",
      "Epoch 14/100\n",
      "40018/40018 [==============================] - 9s 218us/step - loss: 0.0153 - acc: 0.6606 - val_loss: 0.0144 - val_acc: 0.6750\n",
      "Epoch 15/100\n",
      "40018/40018 [==============================] - 8s 192us/step - loss: 0.0153 - acc: 0.6607 - val_loss: 0.0135 - val_acc: 0.6718\n",
      "Epoch 16/100\n",
      "40018/40018 [==============================] - 7s 181us/step - loss: 0.0150 - acc: 0.6642 - val_loss: 0.0139 - val_acc: 0.6552\n",
      "Epoch 17/100\n",
      "40018/40018 [==============================] - 9s 219us/step - loss: 0.0150 - acc: 0.6656 - val_loss: 0.0146 - val_acc: 0.6749\n",
      "Epoch 18/100\n",
      "40018/40018 [==============================] - 7s 177us/step - loss: 0.0151 - acc: 0.6633 - val_loss: 0.0137 - val_acc: 0.6690\n",
      "Epoch 19/100\n",
      "40018/40018 [==============================] - 7s 163us/step - loss: 0.0149 - acc: 0.6673 - val_loss: 0.0142 - val_acc: 0.6635\n",
      "Epoch 20/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0149 - acc: 0.6658 - val_loss: 0.0143 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0149 - acc: 0.6665 - val_loss: 0.0136 - val_acc: 0.6751\n",
      "Epoch 22/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0148 - acc: 0.6713 - val_loss: 0.0138 - val_acc: 0.6804\n",
      "Epoch 23/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0147 - acc: 0.6710 - val_loss: 0.0137 - val_acc: 0.6698\n",
      "Epoch 24/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0147 - acc: 0.6707 - val_loss: 0.0139 - val_acc: 0.6740\n",
      "Epoch 25/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0146 - acc: 0.6726 - val_loss: 0.0139 - val_acc: 0.6568\n",
      "Epoch 26/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0145 - acc: 0.6744 - val_loss: 0.0143 - val_acc: 0.6646\n",
      "Epoch 27/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0145 - acc: 0.6746 - val_loss: 0.0134 - val_acc: 0.6726\n",
      "Epoch 28/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0144 - acc: 0.6763 - val_loss: 0.0137 - val_acc: 0.6783\n",
      "Epoch 29/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0144 - acc: 0.6754 - val_loss: 0.0137 - val_acc: 0.6766\n",
      "Epoch 30/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0144 - acc: 0.6740 - val_loss: 0.0145 - val_acc: 0.6504\n",
      "Epoch 31/100\n",
      "40018/40018 [==============================] - 7s 173us/step - loss: 0.0143 - acc: 0.6748 - val_loss: 0.0135 - val_acc: 0.6809\n",
      "Epoch 32/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0144 - acc: 0.6731 - val_loss: 0.0138 - val_acc: 0.6763\n",
      "Epoch 33/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0143 - acc: 0.6770 - val_loss: 0.0133 - val_acc: 0.6792\n",
      "Epoch 34/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0142 - acc: 0.6782 - val_loss: 0.0141 - val_acc: 0.6756\n",
      "Epoch 35/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0141 - acc: 0.6780 - val_loss: 0.0138 - val_acc: 0.6834\n",
      "Epoch 36/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0141 - acc: 0.6768 - val_loss: 0.0138 - val_acc: 0.6732\n",
      "Epoch 37/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0141 - acc: 0.6791 - val_loss: 0.0133 - val_acc: 0.6795\n",
      "Epoch 38/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0140 - acc: 0.6789 - val_loss: 0.0137 - val_acc: 0.6746\n",
      "Epoch 39/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0140 - acc: 0.6817 - val_loss: 0.0133 - val_acc: 0.6834\n",
      "Epoch 40/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0139 - acc: 0.6795 - val_loss: 0.0134 - val_acc: 0.6690\n",
      "Epoch 41/100\n",
      "40018/40018 [==============================] - 6s 162us/step - loss: 0.0139 - acc: 0.6804 - val_loss: 0.0137 - val_acc: 0.6764\n",
      "Epoch 42/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0138 - acc: 0.6807 - val_loss: 0.0130 - val_acc: 0.6838\n",
      "Epoch 43/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0138 - acc: 0.6802 - val_loss: 0.0135 - val_acc: 0.6721\n",
      "Epoch 44/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0137 - acc: 0.6815 - val_loss: 0.0132 - val_acc: 0.6792\n",
      "Epoch 45/100\n",
      "40018/40018 [==============================] - 6s 162us/step - loss: 0.0137 - acc: 0.6844 - val_loss: 0.0131 - val_acc: 0.6784\n",
      "Epoch 46/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0136 - acc: 0.6833 - val_loss: 0.0134 - val_acc: 0.6808\n",
      "Epoch 47/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0137 - acc: 0.6859 - val_loss: 0.0142 - val_acc: 0.6675\n",
      "Epoch 48/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0136 - acc: 0.6832 - val_loss: 0.0143 - val_acc: 0.6659\n",
      "Epoch 49/100\n",
      "40018/40018 [==============================] - 7s 169us/step - loss: 0.0136 - acc: 0.6855 - val_loss: 0.0134 - val_acc: 0.6771\n",
      "Epoch 50/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0135 - acc: 0.6872 - val_loss: 0.0137 - val_acc: 0.6805\n",
      "Epoch 51/100\n",
      "40018/40018 [==============================] - 7s 164us/step - loss: 0.0135 - acc: 0.6854 - val_loss: 0.0132 - val_acc: 0.6702\n",
      "Epoch 52/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0135 - acc: 0.6848 - val_loss: 0.0138 - val_acc: 0.6688\n",
      "Epoch 53/100\n",
      "40018/40018 [==============================] - 6s 162us/step - loss: 0.0135 - acc: 0.6824 - val_loss: 0.0132 - val_acc: 0.6741\n",
      "Epoch 54/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0134 - acc: 0.6862 - val_loss: 0.0137 - val_acc: 0.6849\n",
      "Epoch 55/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0134 - acc: 0.6883 - val_loss: 0.0133 - val_acc: 0.6808\n",
      "Epoch 56/100\n",
      "40018/40018 [==============================] - 7s 178us/step - loss: 0.0134 - acc: 0.6870 - val_loss: 0.0132 - val_acc: 0.6789\n",
      "Epoch 57/100\n",
      "40018/40018 [==============================] - 7s 168us/step - loss: 0.0133 - acc: 0.6877 - val_loss: 0.0137 - val_acc: 0.6677\n",
      "Epoch 58/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0132 - acc: 0.6904 - val_loss: 0.0133 - val_acc: 0.6791\n",
      "Epoch 59/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0132 - acc: 0.6912 - val_loss: 0.0133 - val_acc: 0.6751\n",
      "Epoch 60/100\n",
      "40018/40018 [==============================] - 6s 152us/step - loss: 0.0132 - acc: 0.6885 - val_loss: 0.0136 - val_acc: 0.6688\n",
      "Epoch 61/100\n",
      "40018/40018 [==============================] - 6s 151us/step - loss: 0.0132 - acc: 0.6897 - val_loss: 0.0134 - val_acc: 0.6716\n",
      "Epoch 62/100\n",
      "40018/40018 [==============================] - 6s 153us/step - loss: 0.0130 - acc: 0.6936 - val_loss: 0.0131 - val_acc: 0.6807\n",
      "Epoch 63/100\n",
      "40018/40018 [==============================] - 6s 155us/step - loss: 0.0131 - acc: 0.6886 - val_loss: 0.0132 - val_acc: 0.6878\n",
      "Epoch 64/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0130 - acc: 0.6893 - val_loss: 0.0132 - val_acc: 0.6764\n",
      "Epoch 65/100\n",
      "40018/40018 [==============================] - 6s 152us/step - loss: 0.0130 - acc: 0.6918 - val_loss: 0.0136 - val_acc: 0.6732\n",
      "Epoch 66/100\n",
      "40018/40018 [==============================] - 6s 152us/step - loss: 0.0129 - acc: 0.6920 - val_loss: 0.0132 - val_acc: 0.6817\n",
      "Epoch 67/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0128 - acc: 0.6946 - val_loss: 0.0130 - val_acc: 0.6770\n",
      "Epoch 68/100\n",
      "40018/40018 [==============================] - 7s 167us/step - loss: 0.0130 - acc: 0.6926 - val_loss: 0.0133 - val_acc: 0.6779\n",
      "Epoch 69/100\n",
      "40018/40018 [==============================] - 7s 171us/step - loss: 0.0128 - acc: 0.6950 - val_loss: 0.0133 - val_acc: 0.6841\n",
      "Epoch 70/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0129 - acc: 0.6942 - val_loss: 0.0136 - val_acc: 0.6783\n",
      "Epoch 71/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0129 - acc: 0.6938 - val_loss: 0.0133 - val_acc: 0.6794\n",
      "Epoch 72/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0128 - acc: 0.6947 - val_loss: 0.0134 - val_acc: 0.6833\n",
      "Epoch 73/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0128 - acc: 0.6965 - val_loss: 0.0135 - val_acc: 0.6883\n",
      "Epoch 74/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0127 - acc: 0.6944 - val_loss: 0.0135 - val_acc: 0.6813\n",
      "Epoch 75/100\n",
      "40018/40018 [==============================] - 6s 155us/step - loss: 0.0126 - acc: 0.6962 - val_loss: 0.0134 - val_acc: 0.6744\n",
      "Epoch 76/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0126 - acc: 0.6989 - val_loss: 0.0132 - val_acc: 0.6837\n",
      "Epoch 77/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0125 - acc: 0.6979 - val_loss: 0.0134 - val_acc: 0.6906\n",
      "Epoch 78/100\n",
      "40018/40018 [==============================] - 8s 192us/step - loss: 0.0124 - acc: 0.6990 - val_loss: 0.0133 - val_acc: 0.6808\n",
      "Epoch 79/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0126 - acc: 0.6947 - val_loss: 0.0132 - val_acc: 0.6827\n",
      "Epoch 80/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0125 - acc: 0.6968 - val_loss: 0.0131 - val_acc: 0.6761\n",
      "Epoch 81/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0124 - acc: 0.6960 - val_loss: 0.0140 - val_acc: 0.6884\n",
      "Epoch 82/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0124 - acc: 0.7019 - val_loss: 0.0133 - val_acc: 0.6808\n",
      "Epoch 83/100\n",
      "40018/40018 [==============================] - 7s 164us/step - loss: 0.0124 - acc: 0.6961 - val_loss: 0.0131 - val_acc: 0.6815\n",
      "Epoch 84/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0122 - acc: 0.7014 - val_loss: 0.0131 - val_acc: 0.6928\n",
      "Epoch 85/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0123 - acc: 0.7009 - val_loss: 0.0133 - val_acc: 0.6718\n",
      "Epoch 86/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0124 - acc: 0.7000 - val_loss: 0.0134 - val_acc: 0.6805\n",
      "Epoch 87/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0123 - acc: 0.7005 - val_loss: 0.0137 - val_acc: 0.6764\n",
      "Epoch 88/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0122 - acc: 0.7014 - val_loss: 0.0137 - val_acc: 0.6860\n",
      "Epoch 89/100\n",
      "40018/40018 [==============================] - 7s 180us/step - loss: 0.0122 - acc: 0.7022 - val_loss: 0.0133 - val_acc: 0.6878\n",
      "Epoch 90/100\n",
      "40018/40018 [==============================] - 8s 189us/step - loss: 0.0123 - acc: 0.7013 - val_loss: 0.0134 - val_acc: 0.6819\n",
      "Epoch 91/100\n",
      "40018/40018 [==============================] - 9s 214us/step - loss: 0.0122 - acc: 0.7003 - val_loss: 0.0133 - val_acc: 0.6859\n",
      "Epoch 92/100\n",
      "40018/40018 [==============================] - 8s 205us/step - loss: 0.0121 - acc: 0.7035 - val_loss: 0.0139 - val_acc: 0.6745\n",
      "Epoch 93/100\n",
      "40018/40018 [==============================] - 8s 193us/step - loss: 0.0120 - acc: 0.7039 - val_loss: 0.0133 - val_acc: 0.6803\n",
      "Epoch 94/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0121 - acc: 0.7027 - val_loss: 0.0134 - val_acc: 0.6731\n",
      "Epoch 95/100\n",
      "40018/40018 [==============================] - 7s 178us/step - loss: 0.0121 - acc: 0.7026 - val_loss: 0.0136 - val_acc: 0.6724\n",
      "Epoch 96/100\n",
      "40018/40018 [==============================] - 7s 185us/step - loss: 0.0121 - acc: 0.7008 - val_loss: 0.0138 - val_acc: 0.6794\n",
      "Epoch 97/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0120 - acc: 0.7048 - val_loss: 0.0135 - val_acc: 0.6818\n",
      "Epoch 98/100\n",
      "40018/40018 [==============================] - 7s 179us/step - loss: 0.0120 - acc: 0.7049 - val_loss: 0.0134 - val_acc: 0.6830\n",
      "Epoch 99/100\n",
      "40018/40018 [==============================] - 8s 196us/step - loss: 0.0119 - acc: 0.7041 - val_loss: 0.0136 - val_acc: 0.6902\n",
      "Epoch 100/100\n",
      "40018/40018 [==============================] - 7s 186us/step - loss: 0.0120 - acc: 0.7061 - val_loss: 0.0136 - val_acc: 0.6816\n"
     ]
    }
   ],
   "source": [
    "# 9->64->256->512->256->64->3 Softmax MSE ADAM 100 epochs ===== 69% accuracy\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_dim=9))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40018 samples, validate on 9779 samples\n",
      "Epoch 1/25\n",
      "40018/40018 [==============================] - 2s 59us/step - loss: 0.0124 - acc: 0.6921 - val_loss: 0.0137 - val_acc: 0.6700\n",
      "Epoch 2/25\n",
      "40018/40018 [==============================] - 3s 67us/step - loss: 0.0124 - acc: 0.6928 - val_loss: 0.0138 - val_acc: 0.6777\n",
      "Epoch 3/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0124 - acc: 0.6935 - val_loss: 0.0139 - val_acc: 0.6885\n",
      "Epoch 4/25\n",
      "40018/40018 [==============================] - 3s 76us/step - loss: 0.0124 - acc: 0.6922 - val_loss: 0.0137 - val_acc: 0.6709\n",
      "Epoch 5/25\n",
      "40018/40018 [==============================] - 3s 75us/step - loss: 0.0124 - acc: 0.6942 - val_loss: 0.0137 - val_acc: 0.6821\n",
      "Epoch 6/25\n",
      "40018/40018 [==============================] - 3s 73us/step - loss: 0.0124 - acc: 0.6925 - val_loss: 0.0138 - val_acc: 0.6724\n",
      "Epoch 7/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6945 - val_loss: 0.0143 - val_acc: 0.6654\n",
      "Epoch 8/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6926 - val_loss: 0.0137 - val_acc: 0.6785\n",
      "Epoch 9/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0124 - acc: 0.6950 - val_loss: 0.0135 - val_acc: 0.6844\n",
      "Epoch 10/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6956 - val_loss: 0.0137 - val_acc: 0.6768\n",
      "Epoch 11/25\n",
      "40018/40018 [==============================] - 3s 73us/step - loss: 0.0123 - acc: 0.6931 - val_loss: 0.0138 - val_acc: 0.6820\n",
      "Epoch 12/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6943 - val_loss: 0.0140 - val_acc: 0.6709\n",
      "Epoch 13/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6931 - val_loss: 0.0135 - val_acc: 0.6792\n",
      "Epoch 14/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0122 - acc: 0.6949 - val_loss: 0.0138 - val_acc: 0.6666\n",
      "Epoch 15/25\n",
      "40018/40018 [==============================] - 3s 74us/step - loss: 0.0123 - acc: 0.6966 - val_loss: 0.0137 - val_acc: 0.6852\n",
      "Epoch 16/25\n",
      "40018/40018 [==============================] - 3s 72us/step - loss: 0.0123 - acc: 0.6952 - val_loss: 0.0137 - val_acc: 0.6826\n",
      "Epoch 17/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0122 - acc: 0.6959 - val_loss: 0.0137 - val_acc: 0.6875\n",
      "Epoch 18/25\n",
      "40018/40018 [==============================] - 4s 99us/step - loss: 0.0122 - acc: 0.6974 - val_loss: 0.0137 - val_acc: 0.6752\n",
      "Epoch 19/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0122 - acc: 0.6951 - val_loss: 0.0139 - val_acc: 0.6679\n",
      "Epoch 20/25\n",
      "40018/40018 [==============================] - 3s 72us/step - loss: 0.0122 - acc: 0.6954 - val_loss: 0.0142 - val_acc: 0.6814\n",
      "Epoch 21/25\n",
      "40018/40018 [==============================] - 3s 72us/step - loss: 0.0122 - acc: 0.6955 - val_loss: 0.0135 - val_acc: 0.6736\n",
      "Epoch 22/25\n",
      "40018/40018 [==============================] - 3s 75us/step - loss: 0.0122 - acc: 0.6953 - val_loss: 0.0139 - val_acc: 0.6730\n",
      "Epoch 23/25\n",
      "40018/40018 [==============================] - 3s 77us/step - loss: 0.0121 - acc: 0.6952 - val_loss: 0.0138 - val_acc: 0.6741\n",
      "Epoch 24/25\n",
      "40018/40018 [==============================] - 3s 77us/step - loss: 0.0121 - acc: 0.6948 - val_loss: 0.0139 - val_acc: 0.6641\n",
      "Epoch 25/25\n",
      "40018/40018 [==============================] - 3s 82us/step - loss: 0.0121 - acc: 0.6971 - val_loss: 0.0140 - val_acc: 0.6856\n"
     ]
    }
   ],
   "source": [
    "# 9->16->256->16->8->3 Softmax MSE ADAM 100 epochs ===== 70% train accuracy\n",
    "history = model.fit(x_train, y_train, epochs=25, validation_data=(x_val, y_val), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_dim=9))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0910 - acc: 0.6012\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0909 - acc: 0.6051\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0909 - acc: 0.6048\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0910 - acc: 0.6037\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.6022\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 2s 42us/step - loss: 0.0909 - acc: 0.6012\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0909 - acc: 0.6046\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0909 - acc: 0.6040\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.6037\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0909 - acc: 0.6038\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0909 - acc: 0.6050\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 2s 51us/step - loss: 0.0909 - acc: 0.6031\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 3s 54us/step - loss: 0.0909 - acc: 0.6046\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0908 - acc: 0.6037\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 1s 29us/step - loss: 0.0909 - acc: 0.6025\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.6037\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 1s 31us/step - loss: 0.0909 - acc: 0.6043\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0909 - acc: 0.6029\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0908 - acc: 0.6038\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0908 - acc: 0.6024\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0908 - acc: 0.6052\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0908 - acc: 0.6033\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0909 - acc: 0.6038\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0908 - acc: 0.6033\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0908 - acc: 0.6019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141af53fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->3 Softmax MSE ADAM 100 epochs ===== 60% train accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0209 - acc: 0.5924\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0209 - acc: 0.5939\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0209 - acc: 0.5952\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0209 - acc: 0.5927\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.5950\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.5955\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0209 - acc: 0.5947\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5965\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0209 - acc: 0.5964\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5959\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5957\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5958\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5976\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0208 - acc: 0.5952\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0208 - acc: 0.5964\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.5940\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.5956\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0208 - acc: 0.5963\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 1s 31us/step - loss: 0.0208 - acc: 0.5962\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.5965\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0208 - acc: 0.5977\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0208 - acc: 0.5980\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0208 - acc: 0.5973\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 1s 31us/step - loss: 0.0207 - acc: 0.5970\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0207 - acc: 0.5964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141ddc3048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->3 Sigmoid MSE ADAM 100 epochs ====== 60% train accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0164 - acc: 0.6223\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 44us/step - loss: 0.0163 - acc: 0.6223\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0164 - acc: 0.6207\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0163 - acc: 0.6234\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0163 - acc: 0.6220\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0163 - acc: 0.6223\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0163 - acc: 0.6221\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 2s 44us/step - loss: 0.0163 - acc: 0.6221\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 2s 34us/step - loss: 0.0163 - acc: 0.6227\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0163 - acc: 0.6240\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0162 - acc: 0.6227\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6244\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0162 - acc: 0.6232\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0163 - acc: 0.6230\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6226\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0162 - acc: 0.6228\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6217\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0162 - acc: 0.6231\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0162 - acc: 0.6237\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0161 - acc: 0.6252\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6233\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0162 - acc: 0.6235\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 2s 34us/step - loss: 0.0162 - acc: 0.6247\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0162 - acc: 0.6245\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0161 - acc: 0.6242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141b1f3278>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 62% accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0140 - acc: 0.6672\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0140 - acc: 0.6678\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0140 - acc: 0.6667\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0140 - acc: 0.6671\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0140 - acc: 0.6675\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 2s 34us/step - loss: 0.0140 - acc: 0.6688\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0139 - acc: 0.6683\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0140 - acc: 0.6686\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0140 - acc: 0.6687\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6689\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6675\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 2s 45us/step - loss: 0.0139 - acc: 0.6685\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6685\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 45us/step - loss: 0.0139 - acc: 0.6686\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0140 - acc: 0.6677\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6706\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0139 - acc: 0.6705\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6671\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0139 - acc: 0.6696\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0139 - acc: 0.6697\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0139 - acc: 0.6697\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0138 - acc: 0.6687\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6698\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6696\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0139 - acc: 0.6689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141c443668>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->32->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 67% accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 46us/step - loss: 0.0128 - acc: 0.6939\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 3s 67us/step - loss: 0.0128 - acc: 0.6941\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 3s 63us/step - loss: 0.0127 - acc: 0.6950\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 3s 54us/step - loss: 0.0128 - acc: 0.6974\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 3s 54us/step - loss: 0.0128 - acc: 0.6968\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 3s 62us/step - loss: 0.0128 - acc: 0.6950\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0128 - acc: 0.6944\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 3s 58us/step - loss: 0.0128 - acc: 0.6954\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 3s 59us/step - loss: 0.0128 - acc: 0.6937\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 3s 58us/step - loss: 0.0127 - acc: 0.6958\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 3s 60us/step - loss: 0.0127 - acc: 0.6967\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 3s 62us/step - loss: 0.0127 - acc: 0.6951\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6944\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6936\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 3s 59us/step - loss: 0.0127 - acc: 0.6968\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6961\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6961\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 3s 63us/step - loss: 0.0127 - acc: 0.6950\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6963\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0126 - acc: 0.6959\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 3s 56us/step - loss: 0.0126 - acc: 0.6973\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 3s 56us/step - loss: 0.0126 - acc: 0.6971\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0127 - acc: 0.6963\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0126 - acc: 0.6973\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0126 - acc: 0.6973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141e0eec50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->32->64->32->16->8->3 Sigmid MSE ADAM 150 epochs ===== 70% train accuracy \n",
    "##### (Good chance of overfitting, need to check val loss)\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 4s 87us/step - loss: 0.0116 - acc: 0.7096\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 4s 81us/step - loss: 0.0117 - acc: 0.7098\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 4s 91us/step - loss: 0.0116 - acc: 0.7106\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 5s 103us/step - loss: 0.0115 - acc: 0.7114\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 5s 108us/step - loss: 0.0114 - acc: 0.7133\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 5s 103us/step - loss: 0.0114 - acc: 0.7113\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 5s 105us/step - loss: 0.0113 - acc: 0.7135\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 5s 107us/step - loss: 0.0113 - acc: 0.7157\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 5s 105us/step - loss: 0.0113 - acc: 0.7147\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 5s 97us/step - loss: 0.0113 - acc: 0.7154\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 5s 94us/step - loss: 0.0110 - acc: 0.7190\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 5s 102us/step - loss: 0.0111 - acc: 0.7163\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 5s 106us/step - loss: 0.0110 - acc: 0.7193\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 5s 101us/step - loss: 0.0109 - acc: 0.7186\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 5s 99us/step - loss: 0.0109 - acc: 0.7198\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 5s 103us/step - loss: 0.0108 - acc: 0.7211\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 5s 110us/step - loss: 0.0108 - acc: 0.7207\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 5s 107us/step - loss: 0.0107 - acc: 0.7230\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 6s 113us/step - loss: 0.0106 - acc: 0.7230\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 5s 111us/step - loss: 0.0107 - acc: 0.7224\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 5s 109us/step - loss: 0.0106 - acc: 0.7239\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 5s 110us/step - loss: 0.0105 - acc: 0.7265\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 5s 112us/step - loss: 0.0104 - acc: 0.7291\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 5s 110us/step - loss: 0.0105 - acc: 0.7268\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 6s 117us/step - loss: 0.0104 - acc: 0.7274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141eb773c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->32->64->128->256->128->64->32->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 72% train accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
