{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "ip = genfromtxt('input.csv', delimiter=',')\n",
    "color = genfromtxt('color.csv', delimiter=',')\n",
    "test_data = genfromtxt('data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48894, 9), (48894, 3), (231401, 9))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip/=255\n",
    "color/=255\n",
    "test_data/=255\n",
    "ip.shape, color.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dset size - 40044 \n",
      "Test dset size - 9779\n"
     ]
    }
   ],
   "source": [
    "data_size = ip.shape[0]\n",
    "val_split = 0.2\n",
    "val_size = round(val_split*data_size)\n",
    "val_ix = np.random.choice(data_size, val_size)\n",
    "train_ix = np.array(list(set(range(data_size))-set(val_ix)))\n",
    "print('Train dset size - {} \\nTest dset size - {}'.format(train_ix.size, val_ix.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = ip[train_ix], color[train_ix]\n",
    "x_val, y_val = ip[val_ix], color[val_ix]\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=9))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40018 samples, validate on 9779 samples\n",
      "Epoch 1/100\n",
      "40018/40018 [==============================] - 9s 225us/step - loss: 0.0240 - acc: 0.5794 - val_loss: 0.0167 - val_acc: 0.6064\n",
      "Epoch 2/100\n",
      "40018/40018 [==============================] - 7s 173us/step - loss: 0.0181 - acc: 0.6096 - val_loss: 0.0160 - val_acc: 0.6254\n",
      "Epoch 3/100\n",
      "40018/40018 [==============================] - 6s 150us/step - loss: 0.0171 - acc: 0.6245 - val_loss: 0.0152 - val_acc: 0.6296\n",
      "Epoch 4/100\n",
      "40018/40018 [==============================] - 8s 190us/step - loss: 0.0167 - acc: 0.6293 - val_loss: 0.0149 - val_acc: 0.6372\n",
      "Epoch 5/100\n",
      "40018/40018 [==============================] - 8s 201us/step - loss: 0.0165 - acc: 0.6318 - val_loss: 0.0149 - val_acc: 0.6367\n",
      "Epoch 6/100\n",
      "40018/40018 [==============================] - 9s 232us/step - loss: 0.0163 - acc: 0.6381 - val_loss: 0.0164 - val_acc: 0.6139\n",
      "Epoch 7/100\n",
      "40018/40018 [==============================] - 9s 217us/step - loss: 0.0162 - acc: 0.6420 - val_loss: 0.0144 - val_acc: 0.6455\n",
      "Epoch 8/100\n",
      "40018/40018 [==============================] - 7s 170us/step - loss: 0.0160 - acc: 0.6427 - val_loss: 0.0146 - val_acc: 0.6486\n",
      "Epoch 9/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0157 - acc: 0.6495 - val_loss: 0.0152 - val_acc: 0.6615\n",
      "Epoch 10/100\n",
      "40018/40018 [==============================] - 9s 220us/step - loss: 0.0156 - acc: 0.6500 - val_loss: 0.0145 - val_acc: 0.6573\n",
      "Epoch 11/100\n",
      "40018/40018 [==============================] - 8s 189us/step - loss: 0.0156 - acc: 0.6562 - val_loss: 0.0144 - val_acc: 0.6558\n",
      "Epoch 12/100\n",
      "40018/40018 [==============================] - 7s 185us/step - loss: 0.0154 - acc: 0.6573 - val_loss: 0.0144 - val_acc: 0.6739\n",
      "Epoch 13/100\n",
      "40018/40018 [==============================] - 8s 191us/step - loss: 0.0153 - acc: 0.6601 - val_loss: 0.0153 - val_acc: 0.6479\n",
      "Epoch 14/100\n",
      "40018/40018 [==============================] - 9s 218us/step - loss: 0.0153 - acc: 0.6606 - val_loss: 0.0144 - val_acc: 0.6750\n",
      "Epoch 15/100\n",
      "40018/40018 [==============================] - 8s 192us/step - loss: 0.0153 - acc: 0.6607 - val_loss: 0.0135 - val_acc: 0.6718\n",
      "Epoch 16/100\n",
      "40018/40018 [==============================] - 7s 181us/step - loss: 0.0150 - acc: 0.6642 - val_loss: 0.0139 - val_acc: 0.6552\n",
      "Epoch 17/100\n",
      "40018/40018 [==============================] - 9s 219us/step - loss: 0.0150 - acc: 0.6656 - val_loss: 0.0146 - val_acc: 0.6749\n",
      "Epoch 18/100\n",
      "40018/40018 [==============================] - 7s 177us/step - loss: 0.0151 - acc: 0.6633 - val_loss: 0.0137 - val_acc: 0.6690\n",
      "Epoch 19/100\n",
      "40018/40018 [==============================] - 7s 163us/step - loss: 0.0149 - acc: 0.6673 - val_loss: 0.0142 - val_acc: 0.6635\n",
      "Epoch 20/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0149 - acc: 0.6658 - val_loss: 0.0143 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0149 - acc: 0.6665 - val_loss: 0.0136 - val_acc: 0.6751\n",
      "Epoch 22/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0148 - acc: 0.6713 - val_loss: 0.0138 - val_acc: 0.6804\n",
      "Epoch 23/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0147 - acc: 0.6710 - val_loss: 0.0137 - val_acc: 0.6698\n",
      "Epoch 24/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0147 - acc: 0.6707 - val_loss: 0.0139 - val_acc: 0.6740\n",
      "Epoch 25/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0146 - acc: 0.6726 - val_loss: 0.0139 - val_acc: 0.6568\n",
      "Epoch 26/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0145 - acc: 0.6744 - val_loss: 0.0143 - val_acc: 0.6646\n",
      "Epoch 27/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0145 - acc: 0.6746 - val_loss: 0.0134 - val_acc: 0.6726\n",
      "Epoch 28/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0144 - acc: 0.6763 - val_loss: 0.0137 - val_acc: 0.6783\n",
      "Epoch 29/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0144 - acc: 0.6754 - val_loss: 0.0137 - val_acc: 0.6766\n",
      "Epoch 30/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0144 - acc: 0.6740 - val_loss: 0.0145 - val_acc: 0.6504\n",
      "Epoch 31/100\n",
      "40018/40018 [==============================] - 7s 173us/step - loss: 0.0143 - acc: 0.6748 - val_loss: 0.0135 - val_acc: 0.6809\n",
      "Epoch 32/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0144 - acc: 0.6731 - val_loss: 0.0138 - val_acc: 0.6763\n",
      "Epoch 33/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0143 - acc: 0.6770 - val_loss: 0.0133 - val_acc: 0.6792\n",
      "Epoch 34/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0142 - acc: 0.6782 - val_loss: 0.0141 - val_acc: 0.6756\n",
      "Epoch 35/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0141 - acc: 0.6780 - val_loss: 0.0138 - val_acc: 0.6834\n",
      "Epoch 36/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0141 - acc: 0.6768 - val_loss: 0.0138 - val_acc: 0.6732\n",
      "Epoch 37/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0141 - acc: 0.6791 - val_loss: 0.0133 - val_acc: 0.6795\n",
      "Epoch 38/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0140 - acc: 0.6789 - val_loss: 0.0137 - val_acc: 0.6746\n",
      "Epoch 39/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0140 - acc: 0.6817 - val_loss: 0.0133 - val_acc: 0.6834\n",
      "Epoch 40/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0139 - acc: 0.6795 - val_loss: 0.0134 - val_acc: 0.6690\n",
      "Epoch 41/100\n",
      "40018/40018 [==============================] - 6s 162us/step - loss: 0.0139 - acc: 0.6804 - val_loss: 0.0137 - val_acc: 0.6764\n",
      "Epoch 42/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0138 - acc: 0.6807 - val_loss: 0.0130 - val_acc: 0.6838\n",
      "Epoch 43/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0138 - acc: 0.6802 - val_loss: 0.0135 - val_acc: 0.6721\n",
      "Epoch 44/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0137 - acc: 0.6815 - val_loss: 0.0132 - val_acc: 0.6792\n",
      "Epoch 45/100\n",
      "40018/40018 [==============================] - 6s 162us/step - loss: 0.0137 - acc: 0.6844 - val_loss: 0.0131 - val_acc: 0.6784\n",
      "Epoch 46/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0136 - acc: 0.6833 - val_loss: 0.0134 - val_acc: 0.6808\n",
      "Epoch 47/100\n",
      "40018/40018 [==============================] - 6s 160us/step - loss: 0.0137 - acc: 0.6859 - val_loss: 0.0142 - val_acc: 0.6675\n",
      "Epoch 48/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0136 - acc: 0.6832 - val_loss: 0.0143 - val_acc: 0.6659\n",
      "Epoch 49/100\n",
      "40018/40018 [==============================] - 7s 169us/step - loss: 0.0136 - acc: 0.6855 - val_loss: 0.0134 - val_acc: 0.6771\n",
      "Epoch 50/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0135 - acc: 0.6872 - val_loss: 0.0137 - val_acc: 0.6805\n",
      "Epoch 51/100\n",
      "40018/40018 [==============================] - 7s 164us/step - loss: 0.0135 - acc: 0.6854 - val_loss: 0.0132 - val_acc: 0.6702\n",
      "Epoch 52/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0135 - acc: 0.6848 - val_loss: 0.0138 - val_acc: 0.6688\n",
      "Epoch 53/100\n",
      "40018/40018 [==============================] - 6s 162us/step - loss: 0.0135 - acc: 0.6824 - val_loss: 0.0132 - val_acc: 0.6741\n",
      "Epoch 54/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0134 - acc: 0.6862 - val_loss: 0.0137 - val_acc: 0.6849\n",
      "Epoch 55/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0134 - acc: 0.6883 - val_loss: 0.0133 - val_acc: 0.6808\n",
      "Epoch 56/100\n",
      "40018/40018 [==============================] - 7s 178us/step - loss: 0.0134 - acc: 0.6870 - val_loss: 0.0132 - val_acc: 0.6789\n",
      "Epoch 57/100\n",
      "40018/40018 [==============================] - 7s 168us/step - loss: 0.0133 - acc: 0.6877 - val_loss: 0.0137 - val_acc: 0.6677\n",
      "Epoch 58/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0132 - acc: 0.6904 - val_loss: 0.0133 - val_acc: 0.6791\n",
      "Epoch 59/100\n",
      "40018/40018 [==============================] - 6s 154us/step - loss: 0.0132 - acc: 0.6912 - val_loss: 0.0133 - val_acc: 0.6751\n",
      "Epoch 60/100\n",
      "40018/40018 [==============================] - 6s 152us/step - loss: 0.0132 - acc: 0.6885 - val_loss: 0.0136 - val_acc: 0.6688\n",
      "Epoch 61/100\n",
      "40018/40018 [==============================] - 6s 151us/step - loss: 0.0132 - acc: 0.6897 - val_loss: 0.0134 - val_acc: 0.6716\n",
      "Epoch 62/100\n",
      "40018/40018 [==============================] - 6s 153us/step - loss: 0.0130 - acc: 0.6936 - val_loss: 0.0131 - val_acc: 0.6807\n",
      "Epoch 63/100\n",
      "40018/40018 [==============================] - 6s 155us/step - loss: 0.0131 - acc: 0.6886 - val_loss: 0.0132 - val_acc: 0.6878\n",
      "Epoch 64/100\n",
      "40018/40018 [==============================] - 6s 158us/step - loss: 0.0130 - acc: 0.6893 - val_loss: 0.0132 - val_acc: 0.6764\n",
      "Epoch 65/100\n",
      "40018/40018 [==============================] - 6s 152us/step - loss: 0.0130 - acc: 0.6918 - val_loss: 0.0136 - val_acc: 0.6732\n",
      "Epoch 66/100\n",
      "40018/40018 [==============================] - 6s 152us/step - loss: 0.0129 - acc: 0.6920 - val_loss: 0.0132 - val_acc: 0.6817\n",
      "Epoch 67/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0128 - acc: 0.6946 - val_loss: 0.0130 - val_acc: 0.6770\n",
      "Epoch 68/100\n",
      "40018/40018 [==============================] - 7s 167us/step - loss: 0.0130 - acc: 0.6926 - val_loss: 0.0133 - val_acc: 0.6779\n",
      "Epoch 69/100\n",
      "40018/40018 [==============================] - 7s 171us/step - loss: 0.0128 - acc: 0.6950 - val_loss: 0.0133 - val_acc: 0.6841\n",
      "Epoch 70/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0129 - acc: 0.6942 - val_loss: 0.0136 - val_acc: 0.6783\n",
      "Epoch 71/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0129 - acc: 0.6938 - val_loss: 0.0133 - val_acc: 0.6794\n",
      "Epoch 72/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0128 - acc: 0.6947 - val_loss: 0.0134 - val_acc: 0.6833\n",
      "Epoch 73/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0128 - acc: 0.6965 - val_loss: 0.0135 - val_acc: 0.6883\n",
      "Epoch 74/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0127 - acc: 0.6944 - val_loss: 0.0135 - val_acc: 0.6813\n",
      "Epoch 75/100\n",
      "40018/40018 [==============================] - 6s 155us/step - loss: 0.0126 - acc: 0.6962 - val_loss: 0.0134 - val_acc: 0.6744\n",
      "Epoch 76/100\n",
      "40018/40018 [==============================] - 6s 156us/step - loss: 0.0126 - acc: 0.6989 - val_loss: 0.0132 - val_acc: 0.6837\n",
      "Epoch 77/100\n",
      "40018/40018 [==============================] - 7s 165us/step - loss: 0.0125 - acc: 0.6979 - val_loss: 0.0134 - val_acc: 0.6906\n",
      "Epoch 78/100\n",
      "40018/40018 [==============================] - 8s 192us/step - loss: 0.0124 - acc: 0.6990 - val_loss: 0.0133 - val_acc: 0.6808\n",
      "Epoch 79/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0126 - acc: 0.6947 - val_loss: 0.0132 - val_acc: 0.6827\n",
      "Epoch 80/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0125 - acc: 0.6968 - val_loss: 0.0131 - val_acc: 0.6761\n",
      "Epoch 81/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0124 - acc: 0.6960 - val_loss: 0.0140 - val_acc: 0.6884\n",
      "Epoch 82/100\n",
      "40018/40018 [==============================] - 7s 166us/step - loss: 0.0124 - acc: 0.7019 - val_loss: 0.0133 - val_acc: 0.6808\n",
      "Epoch 83/100\n",
      "40018/40018 [==============================] - 7s 164us/step - loss: 0.0124 - acc: 0.6961 - val_loss: 0.0131 - val_acc: 0.6815\n",
      "Epoch 84/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0122 - acc: 0.7014 - val_loss: 0.0131 - val_acc: 0.6928\n",
      "Epoch 85/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0123 - acc: 0.7009 - val_loss: 0.0133 - val_acc: 0.6718\n",
      "Epoch 86/100\n",
      "40018/40018 [==============================] - 6s 159us/step - loss: 0.0124 - acc: 0.7000 - val_loss: 0.0134 - val_acc: 0.6805\n",
      "Epoch 87/100\n",
      "40018/40018 [==============================] - 6s 161us/step - loss: 0.0123 - acc: 0.7005 - val_loss: 0.0137 - val_acc: 0.6764\n",
      "Epoch 88/100\n",
      "40018/40018 [==============================] - 6s 157us/step - loss: 0.0122 - acc: 0.7014 - val_loss: 0.0137 - val_acc: 0.6860\n",
      "Epoch 89/100\n",
      "40018/40018 [==============================] - 7s 180us/step - loss: 0.0122 - acc: 0.7022 - val_loss: 0.0133 - val_acc: 0.6878\n",
      "Epoch 90/100\n",
      "40018/40018 [==============================] - 8s 189us/step - loss: 0.0123 - acc: 0.7013 - val_loss: 0.0134 - val_acc: 0.6819\n",
      "Epoch 91/100\n",
      "40018/40018 [==============================] - 9s 214us/step - loss: 0.0122 - acc: 0.7003 - val_loss: 0.0133 - val_acc: 0.6859\n",
      "Epoch 92/100\n",
      "40018/40018 [==============================] - 8s 205us/step - loss: 0.0121 - acc: 0.7035 - val_loss: 0.0139 - val_acc: 0.6745\n",
      "Epoch 93/100\n",
      "40018/40018 [==============================] - 8s 193us/step - loss: 0.0120 - acc: 0.7039 - val_loss: 0.0133 - val_acc: 0.6803\n",
      "Epoch 94/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0121 - acc: 0.7027 - val_loss: 0.0134 - val_acc: 0.6731\n",
      "Epoch 95/100\n",
      "40018/40018 [==============================] - 7s 178us/step - loss: 0.0121 - acc: 0.7026 - val_loss: 0.0136 - val_acc: 0.6724\n",
      "Epoch 96/100\n",
      "40018/40018 [==============================] - 7s 185us/step - loss: 0.0121 - acc: 0.7008 - val_loss: 0.0138 - val_acc: 0.6794\n",
      "Epoch 97/100\n",
      "40018/40018 [==============================] - 7s 174us/step - loss: 0.0120 - acc: 0.7048 - val_loss: 0.0135 - val_acc: 0.6818\n",
      "Epoch 98/100\n",
      "40018/40018 [==============================] - 7s 179us/step - loss: 0.0120 - acc: 0.7049 - val_loss: 0.0134 - val_acc: 0.6830\n",
      "Epoch 99/100\n",
      "40018/40018 [==============================] - 8s 196us/step - loss: 0.0119 - acc: 0.7041 - val_loss: 0.0136 - val_acc: 0.6902\n",
      "Epoch 100/100\n",
      "40018/40018 [==============================] - 7s 186us/step - loss: 0.0120 - acc: 0.7061 - val_loss: 0.0136 - val_acc: 0.6816\n"
     ]
    }
   ],
   "source": [
    "# 9->64->256->512->256->64->3 Softmax MSE ADAM 100 epochs ===== 69% accuracy\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_dim=9))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40018 samples, validate on 9779 samples\n",
      "Epoch 1/25\n",
      "40018/40018 [==============================] - 2s 59us/step - loss: 0.0124 - acc: 0.6921 - val_loss: 0.0137 - val_acc: 0.6700\n",
      "Epoch 2/25\n",
      "40018/40018 [==============================] - 3s 67us/step - loss: 0.0124 - acc: 0.6928 - val_loss: 0.0138 - val_acc: 0.6777\n",
      "Epoch 3/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0124 - acc: 0.6935 - val_loss: 0.0139 - val_acc: 0.6885\n",
      "Epoch 4/25\n",
      "40018/40018 [==============================] - 3s 76us/step - loss: 0.0124 - acc: 0.6922 - val_loss: 0.0137 - val_acc: 0.6709\n",
      "Epoch 5/25\n",
      "40018/40018 [==============================] - 3s 75us/step - loss: 0.0124 - acc: 0.6942 - val_loss: 0.0137 - val_acc: 0.6821\n",
      "Epoch 6/25\n",
      "40018/40018 [==============================] - 3s 73us/step - loss: 0.0124 - acc: 0.6925 - val_loss: 0.0138 - val_acc: 0.6724\n",
      "Epoch 7/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6945 - val_loss: 0.0143 - val_acc: 0.6654\n",
      "Epoch 8/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6926 - val_loss: 0.0137 - val_acc: 0.6785\n",
      "Epoch 9/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0124 - acc: 0.6950 - val_loss: 0.0135 - val_acc: 0.6844\n",
      "Epoch 10/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6956 - val_loss: 0.0137 - val_acc: 0.6768\n",
      "Epoch 11/25\n",
      "40018/40018 [==============================] - 3s 73us/step - loss: 0.0123 - acc: 0.6931 - val_loss: 0.0138 - val_acc: 0.6820\n",
      "Epoch 12/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6943 - val_loss: 0.0140 - val_acc: 0.6709\n",
      "Epoch 13/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0123 - acc: 0.6931 - val_loss: 0.0135 - val_acc: 0.6792\n",
      "Epoch 14/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0122 - acc: 0.6949 - val_loss: 0.0138 - val_acc: 0.6666\n",
      "Epoch 15/25\n",
      "40018/40018 [==============================] - 3s 74us/step - loss: 0.0123 - acc: 0.6966 - val_loss: 0.0137 - val_acc: 0.6852\n",
      "Epoch 16/25\n",
      "40018/40018 [==============================] - 3s 72us/step - loss: 0.0123 - acc: 0.6952 - val_loss: 0.0137 - val_acc: 0.6826\n",
      "Epoch 17/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0122 - acc: 0.6959 - val_loss: 0.0137 - val_acc: 0.6875\n",
      "Epoch 18/25\n",
      "40018/40018 [==============================] - 4s 99us/step - loss: 0.0122 - acc: 0.6974 - val_loss: 0.0137 - val_acc: 0.6752\n",
      "Epoch 19/25\n",
      "40018/40018 [==============================] - 3s 70us/step - loss: 0.0122 - acc: 0.6951 - val_loss: 0.0139 - val_acc: 0.6679\n",
      "Epoch 20/25\n",
      "40018/40018 [==============================] - 3s 72us/step - loss: 0.0122 - acc: 0.6954 - val_loss: 0.0142 - val_acc: 0.6814\n",
      "Epoch 21/25\n",
      "40018/40018 [==============================] - 3s 72us/step - loss: 0.0122 - acc: 0.6955 - val_loss: 0.0135 - val_acc: 0.6736\n",
      "Epoch 22/25\n",
      "40018/40018 [==============================] - 3s 75us/step - loss: 0.0122 - acc: 0.6953 - val_loss: 0.0139 - val_acc: 0.6730\n",
      "Epoch 23/25\n",
      "40018/40018 [==============================] - 3s 77us/step - loss: 0.0121 - acc: 0.6952 - val_loss: 0.0138 - val_acc: 0.6741\n",
      "Epoch 24/25\n",
      "40018/40018 [==============================] - 3s 77us/step - loss: 0.0121 - acc: 0.6948 - val_loss: 0.0139 - val_acc: 0.6641\n",
      "Epoch 25/25\n",
      "40018/40018 [==============================] - 3s 82us/step - loss: 0.0121 - acc: 0.6971 - val_loss: 0.0140 - val_acc: 0.6856\n"
     ]
    }
   ],
   "source": [
    "# 9->16->256->16->8->3 Softmax MSE ADAM 100 epochs ===== 70% train accuracy\n",
    "history = model.fit(x_train, y_train, epochs=25, validation_data=(x_val, y_val), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-134da923dacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_dim=9))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0910 - acc: 0.6012\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0909 - acc: 0.6051\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0909 - acc: 0.6048\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0910 - acc: 0.6037\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.6022\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 2s 42us/step - loss: 0.0909 - acc: 0.6012\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0909 - acc: 0.6046\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0909 - acc: 0.6040\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.6037\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0909 - acc: 0.6038\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0909 - acc: 0.6050\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 2s 51us/step - loss: 0.0909 - acc: 0.6031\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 3s 54us/step - loss: 0.0909 - acc: 0.6046\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0908 - acc: 0.6037\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 1s 29us/step - loss: 0.0909 - acc: 0.6025\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0909 - acc: 0.6037\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 1s 31us/step - loss: 0.0909 - acc: 0.6043\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0909 - acc: 0.6029\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0908 - acc: 0.6038\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0908 - acc: 0.6024\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0908 - acc: 0.6052\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0908 - acc: 0.6033\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0909 - acc: 0.6038\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0908 - acc: 0.6033\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0908 - acc: 0.6019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141af53fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->3 Softmax MSE ADAM 100 epochs ===== 60% train accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0209 - acc: 0.5924\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0209 - acc: 0.5939\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0209 - acc: 0.5952\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0209 - acc: 0.5927\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.5950\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.5955\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0209 - acc: 0.5947\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5965\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0209 - acc: 0.5964\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5959\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5957\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5958\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 1s 28us/step - loss: 0.0208 - acc: 0.5976\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0208 - acc: 0.5952\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0208 - acc: 0.5964\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.5940\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.5956\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0208 - acc: 0.5963\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 1s 31us/step - loss: 0.0208 - acc: 0.5962\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.5965\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0208 - acc: 0.5977\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0208 - acc: 0.5980\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0208 - acc: 0.5973\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 1s 31us/step - loss: 0.0207 - acc: 0.5970\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0207 - acc: 0.5964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141ddc3048>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->3 Sigmoid MSE ADAM 100 epochs ====== 60% train accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0164 - acc: 0.6223\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 44us/step - loss: 0.0163 - acc: 0.6223\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 1s 30us/step - loss: 0.0164 - acc: 0.6207\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0163 - acc: 0.6234\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0163 - acc: 0.6220\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0163 - acc: 0.6223\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0163 - acc: 0.6221\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 2s 44us/step - loss: 0.0163 - acc: 0.6221\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 2s 34us/step - loss: 0.0163 - acc: 0.6227\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 2s 32us/step - loss: 0.0163 - acc: 0.6240\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 2s 31us/step - loss: 0.0162 - acc: 0.6227\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6244\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0162 - acc: 0.6232\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 36us/step - loss: 0.0163 - acc: 0.6230\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6226\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0162 - acc: 0.6228\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6217\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0162 - acc: 0.6231\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0162 - acc: 0.6237\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0161 - acc: 0.6252\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 37us/step - loss: 0.0162 - acc: 0.6233\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 2s 35us/step - loss: 0.0162 - acc: 0.6235\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 2s 34us/step - loss: 0.0162 - acc: 0.6247\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0162 - acc: 0.6245\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0161 - acc: 0.6242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141b1f3278>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 62% accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0140 - acc: 0.6672\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0140 - acc: 0.6678\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0140 - acc: 0.6667\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0140 - acc: 0.6671\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0140 - acc: 0.6675\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 2s 34us/step - loss: 0.0140 - acc: 0.6688\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 2s 33us/step - loss: 0.0139 - acc: 0.6683\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0140 - acc: 0.6686\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0140 - acc: 0.6687\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6689\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6675\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 2s 45us/step - loss: 0.0139 - acc: 0.6685\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6685\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 2s 45us/step - loss: 0.0139 - acc: 0.6686\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0140 - acc: 0.6677\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6706\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0139 - acc: 0.6705\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6671\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 2s 38us/step - loss: 0.0139 - acc: 0.6696\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 2s 41us/step - loss: 0.0139 - acc: 0.6697\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0139 - acc: 0.6697\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 2s 40us/step - loss: 0.0138 - acc: 0.6687\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6698\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.6696\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 2s 47us/step - loss: 0.0139 - acc: 0.6689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141c443668>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->32->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 67% accuracy\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "48894/48894 [==============================] - 2s 46us/step - loss: 0.0128 - acc: 0.6939\n",
      "Epoch 2/25\n",
      "48894/48894 [==============================] - 3s 67us/step - loss: 0.0128 - acc: 0.6941\n",
      "Epoch 3/25\n",
      "48894/48894 [==============================] - 3s 63us/step - loss: 0.0127 - acc: 0.6950\n",
      "Epoch 4/25\n",
      "48894/48894 [==============================] - 3s 54us/step - loss: 0.0128 - acc: 0.6974\n",
      "Epoch 5/25\n",
      "48894/48894 [==============================] - 3s 54us/step - loss: 0.0128 - acc: 0.6968\n",
      "Epoch 6/25\n",
      "48894/48894 [==============================] - 3s 62us/step - loss: 0.0128 - acc: 0.6950\n",
      "Epoch 7/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0128 - acc: 0.6944\n",
      "Epoch 8/25\n",
      "48894/48894 [==============================] - 3s 58us/step - loss: 0.0128 - acc: 0.6954\n",
      "Epoch 9/25\n",
      "48894/48894 [==============================] - 3s 59us/step - loss: 0.0128 - acc: 0.6937\n",
      "Epoch 10/25\n",
      "48894/48894 [==============================] - 3s 58us/step - loss: 0.0127 - acc: 0.6958\n",
      "Epoch 11/25\n",
      "48894/48894 [==============================] - 3s 60us/step - loss: 0.0127 - acc: 0.6967\n",
      "Epoch 12/25\n",
      "48894/48894 [==============================] - 3s 62us/step - loss: 0.0127 - acc: 0.6951\n",
      "Epoch 13/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6944\n",
      "Epoch 14/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6936\n",
      "Epoch 15/25\n",
      "48894/48894 [==============================] - 3s 59us/step - loss: 0.0127 - acc: 0.6968\n",
      "Epoch 16/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6961\n",
      "Epoch 17/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6961\n",
      "Epoch 18/25\n",
      "48894/48894 [==============================] - 3s 63us/step - loss: 0.0127 - acc: 0.6950\n",
      "Epoch 19/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0127 - acc: 0.6963\n",
      "Epoch 20/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0126 - acc: 0.6959\n",
      "Epoch 21/25\n",
      "48894/48894 [==============================] - 3s 56us/step - loss: 0.0126 - acc: 0.6973\n",
      "Epoch 22/25\n",
      "48894/48894 [==============================] - 3s 56us/step - loss: 0.0126 - acc: 0.6971\n",
      "Epoch 23/25\n",
      "48894/48894 [==============================] - 3s 55us/step - loss: 0.0127 - acc: 0.6963\n",
      "Epoch 24/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0126 - acc: 0.6973\n",
      "Epoch 25/25\n",
      "48894/48894 [==============================] - 3s 57us/step - loss: 0.0126 - acc: 0.6973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2141e0eec50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9->16->32->64->32->16->8->3 Sigmid MSE ADAM 150 epochs ===== 70% train accuracy \n",
    "##### (Good chance of overfitting, need to check val loss)\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-042e31474b32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 9->16->32->64->128->256->128->64->32->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 72% train accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 9->16->32->64->128->256->128->64->32->16->8->3 Sigmoid MSE ADAM 100 epochs ===== 72% train accuracy\n",
    "model.fit(x_train, y_train, epochs=2500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
